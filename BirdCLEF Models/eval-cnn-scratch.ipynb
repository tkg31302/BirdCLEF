{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "933b21f4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-28T00:39:27.807355Z",
     "iopub.status.busy": "2025-04-28T00:39:27.807024Z",
     "iopub.status.idle": "2025-04-28T00:39:49.937639Z",
     "shell.execute_reply": "2025-04-28T00:39:49.936878Z"
    },
    "papermill": {
     "duration": 22.136725,
     "end_time": "2025-04-28T00:39:49.939303",
     "exception": false,
     "start_time": "2025-04-28T00:39:27.802578",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-28 00:39:37.528962: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1745800777.799332      13 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1745800777.878277      13 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import math\n",
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from flax import nnx\n",
    "import orbax.checkpoint as ocp\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import tensorflow as tf\n",
    "from tqdm.auto import tqdm\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e78ffff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-28T00:39:49.946762Z",
     "iopub.status.busy": "2025-04-28T00:39:49.946164Z",
     "iopub.status.idle": "2025-04-28T00:39:50.025429Z",
     "shell.execute_reply": "2025-04-28T00:39:50.024513Z"
    },
    "papermill": {
     "duration": 0.084582,
     "end_time": "2025-04-28T00:39:50.027134",
     "exception": false,
     "start_time": "2025-04-28T00:39:49.942552",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import kagglehub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb6f32eb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-28T00:39:50.034122Z",
     "iopub.status.busy": "2025-04-28T00:39:50.033828Z",
     "iopub.status.idle": "2025-04-28T00:39:50.044775Z",
     "shell.execute_reply": "2025-04-28T00:39:50.043811Z"
    },
    "papermill": {
     "duration": 0.016017,
     "end_time": "2025-04-28T00:39:50.046134",
     "exception": false,
     "start_time": "2025-04-28T00:39:50.030117",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test soundscapes directory exists: True\n",
      "Taxonomy CSV exists: True\n",
      "Submission CSV exists: True\n",
      "Model path exists: True\n"
     ]
    }
   ],
   "source": [
    "class CFG:\n",
    "    \"\"\"\n",
    "    Configuration for BirdCLEF-2025 inference pipeline.\n",
    "    \"\"\"\n",
    "    test_soundscapes = '/kaggle/input/birdclef-2025/test_soundscapes'\n",
    "    submission_csv    = '/kaggle/input/birdclef-2025/sample_submission.csv'\n",
    "    taxonomy_csv      = '/kaggle/input/birdclef-2025/taxonomy.csv'\n",
    "    model_path        = '/kaggle/input/birdclef-cnn-baseline/flax/default/1'\n",
    "\n",
    "    FS          = 32000       # Sampling rate\n",
    "    WINDOW_SIZE = 5           # Segment duration (seconds)\n",
    "    N_MELS      = 128         # Mel bands\n",
    "    HOP_LENGTH  = 512         # STFT hop length\n",
    "    N_FRAMES    = math.ceil((WINDOW_SIZE * FS) / HOP_LENGTH)  # Time frames per segment\n",
    "\n",
    "    BATCH_SIZE  = 32          # Inference batch size\n",
    "\n",
    "# print(\"Downloading model via kagglehub...\")\n",
    "# model_path = kagglehub.model_download(\"nikhilpaleti/birdclef-cnn-baseline\")\n",
    "# print(f\"Model downloaded to: {model_path}\")\n",
    "# CFG.model_path = model_path\n",
    "\n",
    "# Check if all data is available\n",
    "print(f\"Test soundscapes directory exists: {os.path.exists(CFG.test_soundscapes)}\")\n",
    "print(f\"Taxonomy CSV exists: {os.path.exists(CFG.taxonomy_csv)}\")\n",
    "print(f\"Submission CSV exists: {os.path.exists(CFG.submission_csv)}\")\n",
    "print(f\"Model path exists: {os.path.exists(CFG.model_path)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77725269",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-28T00:39:50.054125Z",
     "iopub.status.busy": "2025-04-28T00:39:50.053239Z",
     "iopub.status.idle": "2025-04-28T00:39:50.059002Z",
     "shell.execute_reply": "2025-04-28T00:39:50.058245Z"
    },
    "papermill": {
     "duration": 0.011131,
     "end_time": "2025-04-28T00:39:50.060359",
     "exception": false,
     "start_time": "2025-04-28T00:39:50.049228",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def setup_logging():\n",
    "    logging.basicConfig(\n",
    "        format='%(asctime)s %(levelname)s: %(message)s',\n",
    "        level=logging.INFO\n",
    "    )\n",
    "    \n",
    "def build_label_encoder(taxonomy_csv: str):\n",
    "    logging.info(f'Loading taxonomy from {taxonomy_csv}')\n",
    "    df = pd.read_csv(taxonomy_csv)\n",
    "    labels = sorted(df['primary_label'].astype(str).unique())\n",
    "    le = LabelEncoder().fit(labels)\n",
    "    num_classes = len(le.classes_)\n",
    "    logging.info(f'Found {num_classes} classes')\n",
    "    return le, num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c8e859f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-28T00:39:50.067032Z",
     "iopub.status.busy": "2025-04-28T00:39:50.066762Z",
     "iopub.status.idle": "2025-04-28T00:39:50.072608Z",
     "shell.execute_reply": "2025-04-28T00:39:50.071811Z"
    },
    "papermill": {
     "duration": 0.010888,
     "end_time": "2025-04-28T00:39:50.074162",
     "exception": false,
     "start_time": "2025-04-28T00:39:50.063274",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def process_audio_segment(y: np.ndarray, cfg: CFG) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Compute log-mel spectrogram for a fixed-length audio segment.\n",
    "    \"\"\"\n",
    "    S = librosa.feature.melspectrogram(\n",
    "        y=y, sr=cfg.FS, n_mels=cfg.N_MELS,\n",
    "        hop_length=cfg.HOP_LENGTH, fmax=cfg.FS // 2\n",
    "    )\n",
    "    logS = librosa.power_to_db(S, ref=np.max)\n",
    "    if logS.shape[1] < cfg.N_FRAMES:\n",
    "        pad = cfg.N_FRAMES - logS.shape[1]\n",
    "        logS = np.pad(\n",
    "            logS,\n",
    "            ((0,0),(0,pad)),\n",
    "            mode='constant',\n",
    "            constant_values=logS.min()\n",
    "        )\n",
    "    else:\n",
    "        logS = logS[:, :cfg.N_FRAMES]\n",
    "    return logS.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0361356f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-28T00:39:50.080891Z",
     "iopub.status.busy": "2025-04-28T00:39:50.080621Z",
     "iopub.status.idle": "2025-04-28T00:39:50.087170Z",
     "shell.execute_reply": "2025-04-28T00:39:50.086532Z"
    },
    "papermill": {
     "duration": 0.011266,
     "end_time": "2025-04-28T00:39:50.088419",
     "exception": false,
     "start_time": "2025-04-28T00:39:50.077153",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AudioCNN(nnx.Module):\n",
    "    \"\"\"Basic CNN for log-mel spectrograms.\"\"\"\n",
    "    def __init__(self, num_classes: int, rngs: nnx.Rngs):\n",
    "        self.conv1 = nnx.Conv(1, 32, kernel_size=(3,3), rngs=rngs)\n",
    "        self.conv2 = nnx.Conv(32, 64, kernel_size=(3,3), rngs=rngs)\n",
    "        self.pool  = lambda x: nnx.avg_pool(x, window_shape=(2,2), strides=(2,2))\n",
    "        self.dense = nnx.Linear(159744, 128, rngs=rngs)\n",
    "        self.out   = nnx.Linear(128, num_classes, rngs=rngs)\n",
    "\n",
    "    def __call__(self, x: jnp.ndarray) -> jnp.ndarray:\n",
    "        x = self.pool(nnx.relu(self.conv1(x)))\n",
    "        x = self.pool(nnx.relu(self.conv2(x)))\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        x = nnx.sigmoid(self.dense(x))\n",
    "        return self.out(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b6a9325",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-28T00:39:50.095109Z",
     "iopub.status.busy": "2025-04-28T00:39:50.094845Z",
     "iopub.status.idle": "2025-04-28T00:39:50.100048Z",
     "shell.execute_reply": "2025-04-28T00:39:50.099251Z"
    },
    "papermill": {
     "duration": 0.010068,
     "end_time": "2025-04-28T00:39:50.101382",
     "exception": false,
     "start_time": "2025-04-28T00:39:50.091314",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_model(cfg: CFG, num_classes: int) -> nnx.Module:\n",
    "    logging.info('Restoring model checkpoint')\n",
    "    # Create abstract model to get graphdef and state spec\n",
    "    abstract = nnx.eval_shape(lambda: AudioCNN(num_classes, rngs=nnx.Rngs(0)))\n",
    "    graphdef, abstract_state = nnx.split(abstract)\n",
    "    ckpt = ocp.StandardCheckpointer()\n",
    "    restored_state = ckpt.restore(\n",
    "        os.path.join(cfg.model_path, 'model_state'),\n",
    "        abstract_state\n",
    "    )\n",
    "    model = nnx.merge(graphdef, restored_state)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "455bb30d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-28T00:39:50.108357Z",
     "iopub.status.busy": "2025-04-28T00:39:50.108056Z",
     "iopub.status.idle": "2025-04-28T00:39:50.115283Z",
     "shell.execute_reply": "2025-04-28T00:39:50.114534Z"
    },
    "papermill": {
     "duration": 0.012593,
     "end_time": "2025-04-28T00:39:50.116896",
     "exception": false,
     "start_time": "2025-04-28T00:39:50.104303",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def to_tf_inference_dataset(audio_paths, cfg: CFG):\n",
    "    \"\"\"\n",
    "    Build a tf.data.Dataset yielding (spectrogram, row_id) batches.\n",
    "    \"\"\"\n",
    "    def gen():\n",
    "        for path in audio_paths:\n",
    "            y, _ = librosa.load(str(path), sr=cfg.FS)\n",
    "            seg_len = cfg.FS * cfg.WINDOW_SIZE\n",
    "            n_segs = math.ceil(len(y) / seg_len)\n",
    "            soundscape = path.stem\n",
    "            for i in range(n_segs):\n",
    "                start = i * seg_len\n",
    "                end = start + seg_len\n",
    "                seg = y[start:end]\n",
    "                if len(seg) < seg_len:\n",
    "                    seg = np.pad(seg, (0, seg_len - len(seg)), mode='constant')\n",
    "                logS = process_audio_segment(seg, cfg)\n",
    "                row_id = f\"{soundscape}_{(i+1)*cfg.WINDOW_SIZE}\"\n",
    "                yield logS[..., None], row_id\n",
    "\n",
    "    output_signature = (\n",
    "        tf.TensorSpec((cfg.N_MELS, cfg.N_FRAMES, 1), tf.float32),\n",
    "        tf.TensorSpec((), tf.string)\n",
    "    )\n",
    "    ds = tf.data.Dataset.from_generator(\n",
    "        gen,\n",
    "        output_signature=output_signature\n",
    "    )\n",
    "    return ds.batch(cfg.BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed9e90fb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-28T00:39:50.123634Z",
     "iopub.status.busy": "2025-04-28T00:39:50.123306Z",
     "iopub.status.idle": "2025-04-28T00:39:50.132056Z",
     "shell.execute_reply": "2025-04-28T00:39:50.131210Z"
    },
    "papermill": {
     "duration": 0.013742,
     "end_time": "2025-04-28T00:39:50.133503",
     "exception": false,
     "start_time": "2025-04-28T00:39:50.119761",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def inference(cfg: CFG) -> pd.DataFrame:\n",
    "    setup_logging()\n",
    "    le, num_classes = build_label_encoder(cfg.taxonomy_csv)\n",
    "    classes = le.classes_.tolist()\n",
    "\n",
    "    model = load_model(cfg, num_classes)\n",
    "\n",
    "    # Prepare test files and dataset\n",
    "    audio_paths = sorted(Path(cfg.test_soundscapes).glob('*.ogg'))\n",
    "    logging.info(f'Found {len(audio_paths)} test soundscape files')\n",
    "    ds_inf = to_tf_inference_dataset(audio_paths, cfg)\n",
    "\n",
    "    all_row_ids = []\n",
    "    all_preds   = []\n",
    "\n",
    "    # Iterate batches\n",
    "    for specs_batch, ids_batch in tqdm(ds_inf.as_numpy_iterator(), desc='Inference'):  # specs_batch: (B,H,W,1), ids_batch: (B,)\n",
    "        # Run model\n",
    "        logits = model(jnp.array(specs_batch))\n",
    "        probs = jax.nn.sigmoid(logits)\n",
    "        probs_np = np.array(probs)\n",
    "        # Collect\n",
    "        for rid, p in zip(ids_batch, probs_np):\n",
    "            # rid from tf may be bytes\n",
    "            if isinstance(rid, bytes):\n",
    "                rid = rid.decode('utf-8')\n",
    "            all_row_ids.append(rid)\n",
    "            all_preds.append(p)\n",
    "\n",
    "    preds_arr = np.stack(all_preds, axis=0)\n",
    "    # Build DataFrame\n",
    "    df = pd.DataFrame(preds_arr, columns=classes)\n",
    "    df.insert(0, 'row_id', all_row_ids)\n",
    "\n",
    "    # Align with submission template\n",
    "    template = pd.read_csv(cfg.submission_csv)\n",
    "    df = (\n",
    "        df.set_index('row_id')\n",
    "          .reindex(template['row_id'])\n",
    "          .fillna(0.0)\n",
    "          .reset_index()\n",
    "    )\n",
    "    # Ensure all species columns\n",
    "    for col in template.columns[1:]:\n",
    "        if col not in df.columns:\n",
    "            df[col] = 0.0\n",
    "    df = df[template.columns]\n",
    "\n",
    "    # Save\n",
    "    df.to_csv('submission.csv', index=False)\n",
    "    logging.info('Saved submission.csv')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "deb4855e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-28T00:39:50.140347Z",
     "iopub.status.busy": "2025-04-28T00:39:50.140036Z",
     "iopub.status.idle": "2025-04-28T00:39:52.667879Z",
     "shell.execute_reply": "2025-04-28T00:39:52.666653Z"
    },
    "papermill": {
     "duration": 2.53272,
     "end_time": "2025-04-28T00:39:52.669120",
     "exception": true,
     "start_time": "2025-04-28T00:39:50.136400",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/orbax/checkpoint/type_handlers.py:1330: UserWarning: Couldn't find sharding info under RestoreArgs. Populating sharding info from sharding file. Please note restoration time will be slightly increased due to reading from file instead of directly from RestoreArgs. Note also that this option is unsafe when restoring on a different topology than the checkpoint was saved with.\n",
      "  warnings.warn(\n",
      "2025-04-28 00:39:52.102666: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af87b48195314c4cb7218ec531943d2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inference: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "need at least one array to stack",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_13/711076706.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mcfg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCFG\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0msubmission_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubmission_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_13/567921248.py\u001b[0m in \u001b[0;36minference\u001b[0;34m(cfg)\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0mall_preds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0mpreds_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_preds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m     \u001b[0;31m# Build DataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numpy/core/shape_base.py\u001b[0m in \u001b[0;36mstack\u001b[0;34m(arrays, axis, out, dtype, casting)\u001b[0m\n\u001b[1;32m    443\u001b[0m     \u001b[0marrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0masanyarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0marr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 445\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'need at least one array to stack'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[0mshapes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0marr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: need at least one array to stack"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    cfg = CFG()\n",
    "    submission_df = inference(cfg)\n",
    "    print(submission_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55a3628",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 11361821,
     "isSourceIdPinned": false,
     "sourceId": 91844,
     "sourceType": "competition"
    },
    {
     "isSourceIdPinned": false,
     "modelId": 320917,
     "modelInstanceId": 300361,
     "sourceId": 361259,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 31012,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 33.161242,
   "end_time": "2025-04-28T00:39:56.044289",
   "environment_variables": {},
   "exception": true,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-04-28T00:39:22.883047",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "1b7d5f41665244a0999e7cd2bccf3027": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_3599b33e698e40b8b85079f590cdc585",
       "placeholder": "​",
       "style": "IPY_MODEL_43f09228758144f7a165b39af570d642",
       "tabbable": null,
       "tooltip": null,
       "value": "Inference: "
      }
     },
     "2a359e223fe24474bf05cb92fe626f0f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "33cdc6b417a749348b65b71a5796c2f4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "3599b33e698e40b8b85079f590cdc585": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "43f09228758144f7a165b39af570d642": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "5694db2e12294881b480182ab24f169f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_2a359e223fe24474bf05cb92fe626f0f",
       "placeholder": "​",
       "style": "IPY_MODEL_eea14769ea844b2bb0b522283baf32cd",
       "tabbable": null,
       "tooltip": null,
       "value": " 0/? [00:00&lt;?, ?it/s]"
      }
     },
     "75bb0b53edd14bcaa1b44fcfcd6fa484": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_d60caa45c5744f71969f8d6d733308e5",
       "max": 1.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_33cdc6b417a749348b65b71a5796c2f4",
       "tabbable": null,
       "tooltip": null,
       "value": 0.0
      }
     },
     "a6c08a23c50a485a8a848d269a65caf3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "af87b48195314c4cb7218ec531943d2f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_1b7d5f41665244a0999e7cd2bccf3027",
        "IPY_MODEL_75bb0b53edd14bcaa1b44fcfcd6fa484",
        "IPY_MODEL_5694db2e12294881b480182ab24f169f"
       ],
       "layout": "IPY_MODEL_a6c08a23c50a485a8a848d269a65caf3",
       "tabbable": null,
       "tooltip": null
      }
     },
     "d60caa45c5744f71969f8d6d733308e5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": "20px"
      }
     },
     "eea14769ea844b2bb0b522283baf32cd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
